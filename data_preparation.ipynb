{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "803ac6fe-2d50-4ef9-8164-1c0d42be2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import re\n",
    "from defines import coordinates_dict\n",
    "import glob\n",
    "import difflib\n",
    "import pickle\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e53bc-7fbc-4168-9840-a42ae48eaab5",
   "metadata": {},
   "source": [
    "### ToDO \n",
    "- All csv files\n",
    "- All cleaned csv files\n",
    "- All cleaned csv files with enriched with nee data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a46e243-0164-477a-90d9-1d67c82b170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files in the folder:\n",
      "./local_data/data/610.csv\n",
      "./local_data/data/617.csv\n",
      "./local_data/data/616.csv\n",
      "./local_data/data/621.csv\n",
      "./local_data/data/625.csv\n",
      "./local_data/data/615.csv\n",
      "./local_data/data/618.csv\n",
      "./local_data/data/614.csv\n",
      "./local_data/data/624.csv\n",
      "./local_data/data/619.csv\n",
      "./local_data/data/622.csv\n",
      "./local_data/data/613.csv\n",
      "./local_data/data/623.csv\n",
      "./local_data/data/627.csv\n",
      "./local_data/data/612.csv\n",
      "./local_data/data/620.csv\n",
      "./local_data/data/609.csv\n"
     ]
    }
   ],
   "source": [
    "# Get all csv files \n",
    "\n",
    "folder_path = \"./local_data/data/\"  # Replace with the path to your folder\n",
    "csv_files = glob.glob(f\"{folder_path}/*.csv\")\n",
    "\n",
    "# Display the list of CSV files\n",
    "print(\"CSV files in the folder:\")\n",
    "for file_path in csv_files:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de62b70-4c0c-4494-8246-2989edbca54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_df(df):\n",
    "    ## columns rotation rules\n",
    "     return df.melt(id_vars=[\"Unnamed: 0\"], var_name=\"location\", value_name=\"organismQuantity\") # or treat as locality\n",
    "\n",
    "def rename_columns(df):\n",
    "    return df.rename(columns={'Unnamed: 0':'scientificName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a767859d-9fcd-4600-a310-2a112d67fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replacement values rules\n",
    "# df = df.replace(to_replace=['+', '‒'], value=['present', 'absent'])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b786340-a6f8-4aef-936b-445a7e2662ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\*'\n",
      "/tmp/ipykernel_19045/3356128429.py:14: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  text = re.sub('^[0-9.\\*]*', '', text, count=1)\n"
     ]
    }
   ],
   "source": [
    "## Get the correct names of scientific species\n",
    "\n",
    "# loaded dictionary\n",
    "\n",
    "def get_scientificname_dict():\n",
    "    with open('./local_data/taxon/taxon_dictionary.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# Clean and correct names\n",
    "def remove_number(text):\n",
    "    if text !=text:\n",
    "        return text\n",
    "    text = re.sub('^[0-9.\\*]*', '', text, count=1)\n",
    "    text = re.sub('^[aA-zZ]\\\\)', '', text, count=1)\n",
    "    return text\n",
    "\n",
    "def replace_commas(text):\n",
    "    if text !=text:\n",
    "        return text\n",
    "    text = re.sub('^, ,', ' ,, ', text)\n",
    "    text = re.sub('^，，', ',,', text)\n",
    "    text = re.sub('^,,', ' ,, ', text)\n",
    "    text = re.sub('^,', ' ,, ', text)\n",
    "    text = re.sub('^, , , ,', ' ,, ,, ', text)\n",
    "    return text\n",
    "\n",
    "def remove_extra_space(text):\n",
    "    if text !=text:\n",
    "        return text\n",
    "    text = re.sub(' +', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def normalize_to_ascii(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "def remove_roman_numerals(string):\n",
    "    pattern = r'^((M{0,4})(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3}))\\.'\n",
    "    result = re.sub(pattern, '', string)\n",
    "    return result.strip()\n",
    "\n",
    "def complete_species_name(scientificName_list, i):\n",
    "    prev = scientificName_list[i-1].split()[0]\n",
    "    # print('0', scientificName_list[i], '\\t', scientificName_list[i-1])\n",
    "    # print(prev)\n",
    "    scientificName_list[i] = scientificName_list[i].replace(',,', prev)\n",
    "    # print('1', scientificName_list[i], '\\t', scientificName_list[i-1], end='\\n\\n')\n",
    "    return scientificName_list[i]\n",
    "\n",
    "def get_kingdom(text):\n",
    "    url = \"https://api.gbif.org/v1/species/search?q={}&origin=SOURCE&status=ACCEPTED&strict=true\".format(text)\n",
    "    payload = {}\n",
    "    headers = {'Authorization': 'Basic YWtodnlhczA6VnlAJDEyMzQ='}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    try:\n",
    "        if response.status_code==200:\n",
    "            return response.json()['results'][0]['kingdom']\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_close_scname_and_data_gbif(text):\n",
    "    # url = \"https://api.gbif.org/v1/species/search?q={}&origin=SOURCE&status=ACCEPTED&strict=true\".format(text)\n",
    "    url = \"https://api.gbif.org/v1/species/match?name={}&status=ACCEPTED&strict=false&verbose=true\".format(text)\n",
    "    payload = {}\n",
    "    # headers = {'Authorization': 'Basic YWtodnlhczA6VnlAJDEyMzQ='}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    # print(text)\n",
    "    try:\n",
    "        if response.status_code==200:\n",
    "            if 'scientificName' in response.json():\n",
    "                return response.json()['scientificName'],\\\n",
    "                   response.json()['confidence'], response.json()['kingdom'], None, None, None\n",
    "            elif (len(response.json()['alternatives'])>1):\n",
    "                if (response.json()['alternatives'][0]['confidence']==response.json()['alternatives'][1]['confidence']):\n",
    "                    return response.json()['alternatives'][0]['scientificName'],\\\n",
    "                       response.json()['alternatives'][0]['confidence'],\\\n",
    "                       response.json()['alternatives'][0]['kingdom'],\\\n",
    "                       response.json()['alternatives'][1]['scientificName'],\\\n",
    "                       response.json()['alternatives'][1]['confidence'], \\\n",
    "                       response.json()['alternatives'][1]['kingdom']#response.json()['results'][0]['kingdom']\n",
    "                else:\n",
    "                    return response.json()['alternatives'][0]['scientificName'],\\\n",
    "                       response.json()['alternatives'][0]['confidence'], \\\n",
    "                       response.json()['alternatives'][0]['kingdom'], None, None, None\n",
    "            else:\n",
    "                return response.json()['alternatives'][0]['scientificName'],\\\n",
    "                   response.json()['alternatives'][0]['confidence'], \\\n",
    "                   response.json()['alternatives'][0]['kingdom'], None, None, None\n",
    "        else:\n",
    "            return None, None, None, None, None, None\n",
    "    except Exception as e: \n",
    "        print('Except: ', e)\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "def get_close_scname_and_data_from_dict_gbif(sc_name, close_match_sc_dict_gbif):\n",
    "    if sc_name in close_match_sc_dict_gbif:\n",
    "        return close_match_sc_dict_gbif[sc_name]\n",
    "    return (None, None, None, None, None, None)\n",
    "\n",
    "def get_close_scname_and_data_gbif_list(text):\n",
    "    # url = \"https://api.gbif.org/v1/species/search?q={}&origin=SOURCE&status=ACCEPTED&strict=true\".format(text)\n",
    "    url = \"https://api.gbif.org/v1/species/match?name={}&status=ACCEPTED&strict=false&verbose=true\".format(text)\n",
    "    payload = {}\n",
    "    # headers = {'Authorization': 'Basic YWtodnlhczA6VnlAJDEyMzQ='}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    # print(text)\n",
    "    try:\n",
    "        if response.status_code==200:\n",
    "            if 'scientificName' in response.json():\n",
    "                alt_list = []\n",
    "                alt_list.append((response.json()['scientificName'],\\\n",
    "                   response.json()['confidence'], response.json()['kingdom']))\n",
    "                return alt_list, len(alt_list)\n",
    "            else:\n",
    "                try:\n",
    "                    alt_list = []\n",
    "                    # print('len: ', response.json()['alternatives'])\n",
    "                    confidence = response.json()['alternatives'][0]['confidence']\n",
    "                    # print('len: ', response.json()['alternatives'])\n",
    "                    for i in range(len(response.json()['alternatives'])):\n",
    "                        if response.json()['alternatives'][i]['confidence']==confidence:\n",
    "                            alt_list.append((response.json()['alternatives'][i]['scientificName'],\\\n",
    "                                              response.json()['alternatives'][i]['confidence'],\\\n",
    "                                              response.json()['alternatives'][i]['kingdom']))\n",
    "                        else:\n",
    "                            break\n",
    "                    return alt_list, len(alt_list)      \n",
    "                except Exception as e:\n",
    "                    print('Except: ', e, response.text, end='\\n\\n\\n\\n')\n",
    "                    return None, None\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e: \n",
    "        print('Except: ', e, response.text, end='\\n\\n\\n\\n')\n",
    "        return None, None\n",
    "\n",
    "def get_close_scname_and_data_from_dict_gbif_list(sc_name, close_match_sc_dict_gbif_list):\n",
    "    if sc_name in close_match_sc_dict_gbif_list:\n",
    "        return close_match_sc_dict_gbif_list[sc_name]\n",
    "    return None, None\n",
    "\n",
    "def remove_special_characters(input_string):\n",
    "    # Define a regex pattern to match special characters\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    \n",
    "    # Use the sub() method to replace matched patterns with an empty string\n",
    "    result_string = pattern.sub('', input_string)\n",
    "    \n",
    "    return result_string\n",
    "\n",
    "\n",
    "def get_close_scname_and_data(sc_name):\n",
    "    closest_match = difflib.get_close_matches(sc_name, scientificname_dict.keys(), n=1, cutoff=0.5)\n",
    "    if closest_match:\n",
    "        score = difflib.SequenceMatcher(None, sc_name, closest_match[0]).ratio()\n",
    "        return (closest_match[0], score, \n",
    "                scientificname_dict[closest_match[0]]['taxonID'], \n",
    "                scientificname_dict[closest_match[0]]['kingdom'],\n",
    "                scientificname_dict[closest_match[0]]['class'],\n",
    "                scientificname_dict[closest_match[0]]['family'])\n",
    "    return (None, None, None, None, None, None)\n",
    "    \n",
    "    \n",
    "def get_close_scname_and_data_from_dict(sc_name, close_match_sc_dict):\n",
    "    if sc_name in close_match_sc_dict:\n",
    "        return close_match_sc_dict[sc_name]\n",
    "    return (None, None, None, None, None, None)\n",
    "    \n",
    "\n",
    "def getlistlength(text_list):\n",
    "    try:\n",
    "        return len(list(text_list))\n",
    "    except:\n",
    "        return None\n",
    "## Get coordinates using prefilled dict\n",
    "\n",
    "def correct_location_name(location):\n",
    "    closest_match = difflib.get_close_matches(location, coordinates_dict.keys(), n=1, cutoff=0.6)\n",
    "    if closest_match:\n",
    "        return closest_match[0]\n",
    "    return location\n",
    "    \n",
    "def get_coordinates(location):\n",
    "    closest_match = difflib.get_close_matches(location, coordinates_dict.keys(), n=1, cutoff=0.6)\n",
    "    if closest_match:\n",
    "        return coordinates_dict[closest_match[0]]['latitude'], coordinates_dict[closest_match[0]]['longitude']\n",
    "    return None, None\n",
    "\n",
    "def enriched_df(df, image_or_file_id):\n",
    "    df_meta = pd.read_csv('./local_data/imageId_metapath_metadata.csv', encoding='Utf')\n",
    "    df_meta = df_meta[df_meta['Image_Id']==image_or_file_id]\n",
    "    # print (df_meta.head())\n",
    "    df['eventDate'] = int(df_meta['eventDate'].values[0])\n",
    "    df['year'] = int(df_meta['year'].values[0])\n",
    "    df['publicationTitle']= df_meta['publicationTitle'].values[0]\n",
    "    df['publicationYear'] =  int(df_meta['publicationYear'].values[0] )\n",
    "    df['collectionCode'] = df_meta['collectionCode'].values[0]\n",
    "    df['catalogNumber'] = int(df_meta['catalogNumber'].values[0])\n",
    "    df['publicationAuthors'] = df_meta['publicationAuthors'].values[0]\n",
    "    df['authorityURI'] = df_meta['authorityURI'].values[0]\n",
    "    df['authorityValue'] = int(df_meta['authorityValue'].values[0])\n",
    "    \n",
    "    # ToDo --- Fixed Scale\n",
    "    df['organismQuantityType'] = 'Braun-Blanquet Scale'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0863f793-c2cd-4c15-8403-512daa3e1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_close_scname_and_data_gbif('Microcystis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57559c8d-1067-4d6d-acea-2ef1c4bf174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu :  12\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except: Except:   'alternatives''alternatives'\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'Except:   {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}'alternatives'\n",
      "\n",
      "\n",
      "\n",
      " {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}Except: \n",
      "\n",
      "\n",
      "\n",
      " 'alternatives'\n",
      "Except:  Except: 'alternatives'  'alternatives'{\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives'\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "Except:  'alternatives' {\"confidence\":100,\"matchType\":\"NONE\",\"synonym\":false}\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 5.83 s, sys: 1.19 s, total: 7.03 s\n",
      "Wall time: 46.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Cleaning and enriching data\n",
    "scientificname_dict = get_scientificname_dict()\n",
    "# close_match_sc_dict =  dict()\n",
    "close_match_sc_dict_gbif =  dict()\n",
    "close_match_sc_dict_gbif_list =  dict()\n",
    "all_locations = set()\n",
    "\n",
    "\n",
    "def cleaning_data(csv_file_path):\n",
    "    # getfile and melt it according to columns\n",
    "    file_id = int(csv_file_path.split(\"/\")[-1].split(\".\")[0])\n",
    "    df = pd.read_csv(filepath_or_buffer=csv_file_path, encoding='utf-8')\n",
    "    df = melt_df(df)\n",
    "    df = rename_columns(df)\n",
    "\n",
    "    # Creating new columns and feeding data\n",
    "    df['basisOfRecord']='Human Observation'\n",
    "\n",
    "    # cleaning df\n",
    "    df = df.map(remove_extra_space, na_action='ignore')\n",
    "    df['scientificName'] = df['scientificName'].apply(remove_number)\n",
    "    df = df.map(remove_extra_space, na_action='ignore')\n",
    "    df['scientificName'] = df['scientificName'].apply(replace_commas)\n",
    "    df['scientificName'] = df['scientificName'].apply(normalize_to_ascii)\n",
    "    df['scientificName'] = df['scientificName'].apply(remove_roman_numerals)\n",
    "    df = df.map(remove_extra_space, na_action='ignore')\n",
    "    \n",
    "    scientificName_list = df['scientificName'].tolist()\n",
    "    df['scientificName'] = [scientificName_list[0]]+ [complete_species_name(scientificName_list, i) for i, j in enumerate(scientificName_list) if i>0]\n",
    "\n",
    "    # special character treatment\n",
    "    # df['scientificName'] = df['scientificName'].apply(remove_special_characters)\n",
    "\n",
    "    # ToDo ---  taking only 50 rows\n",
    "    # df = df.sample(n=2, random_state=1)\n",
    "    # this API is very Slow\n",
    "    # get and add Kingdom\n",
    "    # df['kingdom'] = df['scientificName'].apply(get_kingdom)\n",
    "\n",
    "#    close_match_sc_dict.update({sc_name:get_close_scname_and_data(sc_name) for sc_name in df['scientificName'].unique().tolist()})\n",
    "    close_match_sc_dict_gbif.update({sc_name:get_close_scname_and_data_gbif(sc_name) for sc_name in df['scientificName'].unique().tolist()})\n",
    "    close_match_sc_dict_gbif_list.update({sc_name:get_close_scname_and_data_gbif_list(sc_name) for sc_name in df['scientificName'].unique().tolist()})\n",
    "    \n",
    "    # print(close_match_sc_dict)\n",
    "    # correcting scientific name according to Taxon data file\n",
    "    df[['scientificNameCloseGbif1', 'matchingScoreGbif1', 'kingdomGbif1', 'scientificNameCloseGbif2', 'matchingScoreGbif2', 'kingdomGbif2']]\\\n",
    "                    = pd.DataFrame(df['scientificName'].\\\n",
    "                                   apply(get_close_scname_and_data_from_dict_gbif, args=(close_match_sc_dict_gbif,)).\\\n",
    "                                   tolist(), index=df.index)\n",
    "    df[['scientificName_matchingScore_kingdom_CloseGbiflist', 'scientificName_matchingScore_kingdom_CloseGbiflistLength']]\\\n",
    "                    = pd.DataFrame(df['scientificName'].\\\n",
    "                                   apply(get_close_scname_and_data_from_dict_gbif_list, args=(close_match_sc_dict_gbif_list,)).\\\n",
    "                                   tolist(), index=df.index)\n",
    "\n",
    "    #df[['scientificNameClose', 'matchingScore', 'taxonID', 'kingdom', 'class', 'family']] = pd.DataFrame(df['scientificName'].\\\n",
    "    #                                                                                          apply(get_close_scname_and_data_from_dict, args=(close_match_sc_dict,)).\\\n",
    "    #                                                                                          tolist(), index=df.index)\n",
    "\n",
    "    ## correct location name\n",
    "    df['location'] = df['location'].apply(correct_location_name)\n",
    "    \n",
    "    ## get coordinates\n",
    "    df['coordinates'] = df['location'].apply(get_coordinates)\n",
    "    df[['latitude', 'longitude']] = pd.DataFrame(df['coordinates'].tolist(), index=df.index)\n",
    "\n",
    "    ## ToDo -  add data from meta data  \n",
    "    df = enriched_df(df, file_id)\n",
    "    df.to_csv('./data/cleaned_data/'+ str(file_id) +'.csv', encoding='utf-8', index=False)\n",
    "    all_locations.update(df['location'].tolist())\n",
    "    # Todo - Remove Break\n",
    "    # break\n",
    "\n",
    "print(\"Number of cpu : \", cpu_count())\n",
    "p = Pool(4)\n",
    "# Todo - only two csv files\n",
    "p.map(cleaning_data, csv_files)\n",
    "\n",
    "# for csv_file_path in csv_files:\n",
    "#    cleaning_data(csv_file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d336d1e-8a55-48ec-9b8d-9188e4388be1",
   "metadata": {},
   "source": [
    "df_taxon = pd.read_csv('./local_data/taxon/Taxon_withoutduplicate_scname.csv', encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",
    "\n",
    "# df_taxon[~df_taxon[['scientificName']].duplicated()].describe(include='all') for Taxon.csv\n",
    "taxon_dict = df_taxon[['taxonID', 'scientificName', 'canonicalName', 'kingdom', 'class', 'family']].set_index('scientificName').to_dict('index')\n",
    "\n",
    "with open('./local_data/taxon/taxon_dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(taxon_dict, f)\n",
    "        \n",
    "with open('./local_data/taxon/taxon_dictionary.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d312b3e7-104d-46de-952b-a1a308805056",
   "metadata": {},
   "source": [
    "# get coordinates\n",
    "geolocator = Nominatim(user_agent=\"your_app_name\")  # Replace 'your_app_name' with a unique name for your application\n",
    "\n",
    "# Function to get coordinates for a location\n",
    "def get_coordinates(location):\n",
    "    try:\n",
    "        # Use geopy to get location coordinates\n",
    "        location_data = geolocator.geocode(location, language='de')\n",
    "        if location_data:\n",
    "            return location_data.latitude, location_data.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing location '{location}': {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to the \"location\" column and create new \"latitude\" and \"longitude\" columns\n",
    "print(df.shape)\n",
    "df['coordinates'] = df['location'].apply(get_coordinates)\n",
    "print(df.shape)\n",
    "df[['latitude', 'longitude']] = pd.DataFrame(df['coordinates'].tolist(), index=df.index)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "# df.to_csv('./data/609_10_records_location_coordinate.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# Display the DataFrame with coordinates\n",
    "print(df[['location', 'latitude', 'longitude']])\n",
    "df[['location', 'latitude', 'longitude']].drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "964d01e1-f83f-45bb-ab57-52c312af3463",
   "metadata": {},
   "source": [
    "## get coordinates\n",
    "\n",
    "# Replace 'your_api_key' with your actual OpenCage Geocoding API key\n",
    "api_key = ''\n",
    "base_url = 'https://api.opencagedata.com/geocode/v1/json'\n",
    "\n",
    "\n",
    "# Function to get coordinates for a location using the OpenCage Geocoding API\n",
    "def get_coordinates(location):\n",
    "    try:\n",
    "        params = {\n",
    "            'q': location,\n",
    "            'key': api_key,\n",
    "            'language': 'en',  # Specify language for results\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['results']:\n",
    "            latitude = data['results'][0]['geometry']['lat']\n",
    "            longitude = data['results'][0]['geometry']['lng']\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing location '{location}': {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to the \"location\" column and create new \"latitude\" and \"longitude\" columns\n",
    "df['coordinates'] = df['location'].apply(get_coordinates)\n",
    "df[['latitude', 'longitude']] = pd.DataFrame(df['coordinates'].tolist(), index=df.index)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = 'output_file.csv'  # Replace 'output_file.csv' with your desired output file path\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the DataFrame with coordinates\n",
    "print(df[['location', 'latitude', 'longitude']])\n",
    "df[['location', 'latitude', 'longitude']].drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "942bb210-d8a8-4164-9263-5db064269e9d",
   "metadata": {},
   "source": [
    "## get coordinates - Translation code\n",
    "\n",
    "import key\n",
    "\n",
    "import importlib\n",
    "importlib.reload(key)\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=key.key)\n",
    "\n",
    "\n",
    "def translate_text_with_chatgpt(text, language=\"en\"):\n",
    "    # Define the prompt for translation\n",
    "    prompt = f\"Translate the following German text to {language}: {text}\"\n",
    "\n",
    "    # Make an API call to ChatGPT for translation\n",
    "    stream = client.chat.completions.create( model=\"gpt-3.5-turbo-1106\", \n",
    "                                            messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "                                            stream=True,)\n",
    "\n",
    "    for chunk in stream:\n",
    "        print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "    \n",
    "    \"\"\"response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",  # You can experiment with different engines\n",
    "        prompt=prompt,\n",
    "        max_tokens=150  # Adjust as needed\n",
    "    )\"\"\"\n",
    "\n",
    "    # Extract the translated text from the response\n",
    "    # translated_text = response.choices[0].text.strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "# Translate the text in the specified column using ChatGPT\n",
    "df['scientificName_en'] = df['scientificName'].apply(lambda x: translate_text_with_chatgpt(x))\n",
    "\n",
    "# Save the translated DataFrame to a new CSV file\n",
    "# df.to_csv(output_csv, index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf811beb-ab11-498d-bcc7-438af889859c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
