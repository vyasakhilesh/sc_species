{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58ef9bd6-bf21-4343-863f-9a5ab2f4f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2347d98d-3783-4bc8-ad5e-ceb67765d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting OccurenceID\n",
    "def merge_data(csv_file_path):\n",
    "    global df_all\n",
    "    global df_meta_all\n",
    "    df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "    df['occurrenceID'] = df['collectionCode']+ '_' + df['catalogNumber'].apply(str)\n",
    "    df_meta = df[['occurrenceID','publicationTitle', 'publicationYear', 'collectionCode', \n",
    "                 'catalogNumber','publicationAuthors', 'authorityURI', 'authorityValue']].drop_duplicates()\n",
    "    df.drop(columns=['publicationTitle', 'publicationYear', 'collectionCode', \n",
    "                 'catalogNumber','publicationAuthors', 'authorityURI', 'authorityValue'], inplace=True )\n",
    "    return (df, df_meta)\n",
    "# Getting Metadata\n",
    "\n",
    "directory_path  = \"./data/final_final_data/**/\"  # Replace with the path to your folder\n",
    "all_csv_files_path  = glob.glob(f\"{directory_path}/*.csv\", recursive=True)\n",
    "# Display the list of CSV files\n",
    "print(f\"CSV files in the folder:{len(all_csv_files_path)}\")\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "df_meta_all = pd.DataFrame()\n",
    "for csv_file_path in all_csv_files_path: #sorted(all_csv_files_path, key=lambda x: Path(x).stem):\n",
    "    print(csv_file_path)\n",
    "    df, df_meta = merge_data(csv_file_path)\n",
    "    df_all = pd.concat([df_all, df])\n",
    "    df_meta_all = pd.concat([df_meta_all, df_meta])\n",
    "\n",
    "df_all.drop_duplicates(inplace=True)\n",
    "df_meta_all.drop_duplicates(inplace=True)\n",
    "df_all.to_csv('./gbif_test_data/test.csv', index=False)\n",
    "df_meta_all.to_csv('./gbif_test_data/test_meta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "72a541e1-ad86-43ad-91f9-c680b643cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Read the large CSV file\n",
    "df = pd.read_csv('./gbif_test_data/test.csv')\n",
    "df_event_all = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Group by the unique ID column and save each group to a separate CSV file\n",
    "for unique_id, group in df.groupby('occurrenceID'):\n",
    "    df_event_occur = pd.DataFrame()\n",
    "    group_reset = group.reset_index(drop=True)\n",
    "    group.drop(columns=['eventDate'], inplace=True)\n",
    "    # print(group_reset.index.tolist())\n",
    "    group['occurrenceID'] = group['occurrenceID']+'_'+ group_reset.index.astype(str)\n",
    "    for unique_id_event, group_event in group.groupby(by=['verbatimLocality', 'year']):\n",
    "        group_event_occr = group_event.drop(columns=['decimalLatitude', 'decimalLongitude', 'year'])\n",
    "        group_event = group_event[['verbatimLocality', 'decimalLatitude', 'decimalLongitude', 'year']]\n",
    "        # event_id for events\n",
    "        event_id = unique_id + '_' + str(int(hashlib.sha256(unique_id_event[0].encode('utf-8')).hexdigest(), 16) % 10**8)\n",
    "        group_event.loc[:,['eventID']] =  event_id\n",
    "        group_event_occr = group_event_occr.join(other=group_event, how='left', lsuffix='_left')\n",
    "        df_event_all = pd.concat([df_event_all, group_event])\n",
    "        group_event_occr.drop(columns=['verbatimLocality', 'verbatimLocality_left'], inplace=True)\n",
    "        # group_event_occr.loc[:, ['eventID']] = \n",
    "        group_event_occr.to_csv(f'./gbif_test_data/eventdata/Event_{event_id}.csv', index=False)\n",
    "df_event_all.drop_duplicates(inplace=True)\n",
    "df_event_all.to_csv('./gbif_test_data/'+'event_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d535f535-4b57-41b7-a4b8-0163628d3400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'8257', '8568', '9506', '2673', '8156', '3156', '7465', '3006', '7870', '3146', '3152', '2981', '2983', '7812', '11868', '2929', '2982', '3131', '7487'}\n"
     ]
    }
   ],
   "source": [
    "# Merge event data files based on tuexen number \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "directory_path = './gbif_test_data/eventdata/'\n",
    "filename_list = [filename for filename in os.listdir(directory_path)]\n",
    "tuexen_unique_no_list = set([filename.split('_')[2] for filename in os.listdir(directory_path) if filename.endswith('.csv')])\n",
    "print(tuexen_unique_no_list)\n",
    "# print(filename_list, tuexen_unique)\n",
    "\n",
    "for tuexen_unique_no in tuexen_unique_no_list:\n",
    "    dfs = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        try:\n",
    "            if tuexen_unique_no in filename:\n",
    "                df = pd.read_csv(os.path.join(directory_path, filename))\n",
    "                dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(tuexen_unique_no)\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df.to_csv('./gbif_test_data/eventdata_combined/'+ 'Event_'+ tuexen_unique_no+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe89274-82a8-4c92-bf65-db0f53556dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def remove_linefeed(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv('./gbif_test_data/event_all.csv', encoding='utf-8')\n",
    "df['verbatimLocality'] = df['verbatimLocality'].apply(remove_linefeed)\n",
    "df.to_csv('./gbif_test_data/'+'event_all_removed_linefeed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811026e7-91d2-4e6d-8bf0-f73cb374ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najas minor all. in Europa einst und jetzt\n",
      "Über einige bemerkenswerte Pflanzenvereine in Litauen\n",
      "Waldgesellschaften des nördlichen Havellandes\n",
      "Die Algenflora Westfalens und der angrenzenden Gebiete\n",
      "Das Klimax-Gebiet der Buchenwälder in den Westkarpathen\n",
      "Die Pflanzengesellschaften des westsächsischen Berg- und Hügellandes (Flußgebiet der Freiberger und Zwickauer Mulde) 2. Teil Die Pflanzengesellschaften der erzgebirgischen Moore\n",
      "Ein Beitrag zur geobotanischen Durchforschung des Steppengebiets im Böhmischen Mittelgebirge\n",
      "Die Pflanzengesellschaften des westsächsischen Berg- und Hügellandes (Flußgebiet der Freiberger und Zwickauer Mulde) 3. Teil Laichkraut-, Röhricht- und Großseggengesellschaften, 4. Teil Die Pflanzengesellschaften der Quellfluren und Bachufer und der Verband der Schwarzerlen-Gesellschaften\n",
      "Zur Kenntnis der Waldgesellschaften im Böhmischen Mittelgebirge (Wälder des Milleschauer Mittelgebirges)\n",
      "Pflanzensoziologische Untersuchungen in der Alpinen Stufe Finnisch-Lapplands\n",
      "Der Hammrich - die Vegatationseinheiten eines Flachmoores an der Unterems\n",
      "Die Vegetation und Oberflächengestaltung der Oberharzer Hochmoore\n",
      "Die Pflanzengesellschaften des westsächsischen Berg- und Hügellandes (Flußgebiet der Freiberger und Zwickauer Mulde) 1. Teil Die Gesellschaft des nackten Teichschlammes (Eleocharetum ovatae)\n",
      "Xerotherme Pflanzengesellschaften der Kovácover Hügel in der Südslowakei\n",
      "Über die Pflanzen, welche den atlantischen Ocean auf der Westküste Europas begleiten. Eine pflanzengeographische Skizze.\n",
      "Eine Pflanzengeographische Übersicht über das Gebiet Kuuttilahti am Sywäri-Swir (Fern-Karelien)\n",
      "Zur Kenntnis der Flora und Vegetation eines Uferabschnitts am Laatokkasee nördlich der Syväri-Mündung\n",
      "Besiedlung und Vegetationsentwicklung auf den jungen Seitenmoränen des großen Aletschgletschers : mit einem Vergleich der Besiedlung im Vorfeld des Rhonegletschers und des Oberen Grindelwaldgletschers\n",
      "Der Zeigerwert der Ackerunkräuter im östlichen Holstein\n"
     ]
    }
   ],
   "source": [
    "# Parse and complete xml file\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./gbif_test_data/test_meta.csv', encoding='utf-8')\n",
    "\n",
    "for _ , row in df.iterrows():\n",
    "    tree =  ET.parse('./gbif_test_data/eml-test-v1.0.xml')\n",
    "    root = tree.getroot()\n",
    "    # for title in root.findall('title'):\n",
    "    root.find('dataset').find('title').text =  row['publicationTitle']\n",
    "    print(root.find('dataset').find('title').text)\n",
    "    tree.write('./gbif_test_data/meta_xml/meta_eml'+row['occurrenceID']+'.xml', encoding='utf-8', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305fa057-6fdf-4d66-a52a-8db6cc67c4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
